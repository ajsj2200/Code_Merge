import threading
import time
import anthropic
import re
import pyperclip
import base64
import json
from streamlit_tree_select import tree_select
import streamlit as st
import os
import pathlib
import textwrap
import google.generativeai as genai
from google.api_core import retry
import concurrent.futures
import openai
from openai import AsyncOpenAI


class Node:
    def __init__(self, label, code="", children=None, id=None):
        self.label = label
        self.code = code
        self.children = children or []
        self.id = id or label

    def add_child(self, node):
        self.children.append(node)

    def remove_child(self, label):
        self.children = [
            child for child in self.children if child.label != label]

    def to_dict(self):
        return {
            "label": self.get_label_with_icon(),
            "value": self.id,
            "code": self.code,
            "children": [child.to_dict() for child in self.children],
            "expand_disabled": self.is_leaf()
        }

    def is_leaf(self):
        return len(self.children) == 0

    def get_label_with_icon(self):
        file_extension_to_emoji = {
            '.py': 'ğŸ',   # Python files
            '.cs': 'ğŸ§©',   # C# files
            '.txt': 'ğŸ“„',  # Text files
            '.md': 'ğŸ“',   # Markdown files
        }

        if os.path.isdir(self.id):
            return f"ğŸ“ {self.label}"
        else:
            if self.id.endswith('.Designer.cs'):
                return f"ğŸ¨ {self.label}"
            else:
                _, extension = os.path.splitext(self.id)
                return f"{file_extension_to_emoji.get(extension, 'ğŸ“„')} {self.label}"


def count_files_in_folder(path, allowed_extensions):
    count = 0
    for root, dirs, files in os.walk(path):
        for file in files:
            if os.path.splitext(file)[1] in allowed_extensions:
                count += 1
    return count


@st.cache_resource
def load_api_key():
    try:
        with open("api_key.txt", "r") as file:
            api_key = file.read().strip()
        return api_key
    except FileNotFoundError:
        st.error("API í‚¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return ""
    except Exception as e:
        st.error(f"API í‚¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return ""


@st.cache_resource
def load_gemini_api_key(filepath):
    return pathlib.Path(filepath).read_text().strip()


@st.cache_resource
def load_favorite_directories(filepath="favorite_directories.txt"):
    try:
        with open(filepath, "r", encoding="utf-8") as file:
            directories = [line.strip()
                           for line in file.readlines() if line.strip()]
        return directories
    except FileNotFoundError:
        st.error("ì¦ê²¨ì°¾ê¸° ê²½ë¡œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return []
    except Exception as e:
        st.error(f"ì¦ê²¨ì°¾ê¸° ê²½ë¡œ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return []


def configure_genai(api_key):
    genai.configure(api_key=api_key)


def get_model(model_name):
    generation_config = {
        "temperature": 0.5,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
        "response_mime_type": "text/plain",
    }

    return genai.GenerativeModel(model_name=model_name, generation_config=generation_config)


def generate_markdown(model, context):
    prompt = f"""
    ë‹¤ìŒ ì§€ì‹œì‚¬í•­ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ Markdown ë¬¸ì„œë¡œ ë³€í™˜í•´ ì£¼ì„¸ìš”:

    ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ë‚´ìš©ì„ ì ˆëŒ€ë¡œ ë³€ê²½í•˜ê±°ë‚˜ ì¶”ê°€, ì‚­ì œí•˜ì§€ ë§ˆì„¸ìš”.

    ë‹¨ì–´, ë¬¸ì¥, ë‹¨ë½ ë“± ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ìˆ˜ì •ë˜ì–´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
    ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì™€ ë©”ì‹œì§€ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.


    Markdown ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”í•˜ê³  ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.

    ì œëª©, ë¶€ì œëª©, ëª©ë¡, ì¸ìš©êµ¬, ì½”ë“œ ë¸”ë¡ ë“± ì ì ˆí•œ ìš”ì†Œë¥¼ í™œìš©í•˜ì„¸ìš”.
    ì›ë³¸ í…ìŠ¤íŠ¸ì˜ êµ¬ì¡°ì™€ íë¦„ì„ ìµœëŒ€í•œ ë°˜ì˜í•˜ë„ë¡ ë…¸ë ¥í•˜ì„¸ìš”.


    ì›ë³¸ í…ìŠ¤íŠ¸ ì´ì™¸ì˜ ì–´ë–¤ ë‚´ìš©ë„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

    ì„¤ëª…, í•´ì„, ì˜ê²¬ ë“± ì–´ë–¤ ì¶”ê°€ ì •ë³´ë„ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

    ë³€í™˜í•  í…ìŠ¤íŠ¸:
    {context}
    """
    response = model.generate_content(
        prompt, request_options={'retry': retry.Retry()})
    return response


def process_response(response):
    try:
        markdown_text = response.candidates[0].content.parts[0].text
        return markdown_text
    except KeyError:
        return ""


def display_markdown(markdown_text):
    display(Markdown(markdown_text))


def chunk_text(text, chunk_size=500, overlap_size=100):
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap_size
    return chunks


def count_files_in_directory(path, allowed_extensions):
    total_files = 0
    for root, dirs, files in os.walk(path):
        for file in files:
            if os.path.splitext(file)[1] in allowed_extensions:
                total_files += 1
    return total_files


def read_file(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
    except Exception as e:
        print(f"Error reading file: {file_path}")
        print(str(e))
        return None


def write_file(file_path, content):
    try:
        with open(file_path, 'w', encoding='utf-8') as file:
            file.write(content)
    except Exception as e:
        print(f"Error writing to file: {file_path}")
        print(str(e))


def directory_to_tree(path, allowed_extensions=None, progress=None, processed_files=0, total_files=1):
    if allowed_extensions is None:
        allowed_extensions = ['.cs', '.py', '.txt', '.md']

    name = os.path.basename(path)
    if os.path.isdir(path):
        file_count = count_files_in_folder(path, allowed_extensions)
        name = f"{name} ({file_count}ê°œ íŒŒì¼"  # í´ë” ì´ë¦„ ë’¤ì— íŒŒì¼ ê°œìˆ˜ ì¶”ê°€
    node = Node(name, id=path)

    if progress is None:
        total_files = count_files_in_directory(path, allowed_extensions)
        progress = st.progress(0)

    if os.path.isdir(path):
        children = os.listdir(path)
        folders = sorted(
            [child for child in children if os.path.isdir(os.path.join(path, child))])
        files = sorted(
            [child for child in children if not os.path.isdir(os.path.join(path, child))])
        sorted_children = folders + files  # í´ë”ê°€ íŒŒì¼ë³´ë‹¤ ë¨¼ì € ì˜¤ë„ë¡ ì •ë ¬

        for child in sorted_children:
            child_path = os.path.join(path, child)
            try:
                child_node, processed_files = directory_to_tree(
                    child_path, allowed_extensions, progress, processed_files, total_files)
                if child_node.children or child_node.code:
                    node.add_child(child_node)
            except Exception as e:
                print(f"Error processing child node: {child_path}")
                print(str(e))
    else:
        file_extension = os.path.splitext(path)[1]
        if file_extension in allowed_extensions:
            node.code = path  # íŒŒì¼ ê²½ë¡œë§Œ ì €ì¥
            processed_files += 1
            progress.progress(processed_files / total_files)

    # ë‹¤ ëë‚˜ë©´ progress bar ì œê±°
    if processed_files == total_files:
        progress.empty()

    return node, processed_files


@st.cache_resource
def load_prompts():
    prompts = {}
    prompts_folder = "prompts"
    if not os.path.exists(prompts_folder):
        st.error(f"í”„ë¡¬í”„íŠ¸ í´ë” '{prompts_folder}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return prompts

    for filename in os.listdir(prompts_folder):
        if filename.endswith(".txt"):
            filepath = os.path.join(prompts_folder, filename)
            try:
                with open(filepath, "r", encoding="utf-8") as file:
                    prompts[filename] = file.read()
            except FileNotFoundError:
                st.error(f"{filepath} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                prompts[filename] = ""
            except Exception as e:
                st.error(f"{filepath} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                prompts[filename] = ""

    return prompts


@st.cache_resource
def load_api_key():
    try:
        with open("api_key.txt", "r") as file:
            api_key = file.read().strip()
        return api_key
    except FileNotFoundError:
        st.error("API í‚¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return ""
    except Exception as e:
        st.error(f"API í‚¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return ""


@st.cache_resource
def load_openai_api_key():
    try:
        with open("openai_api_key.txt", "r") as file:
            api_key = file.read().strip()
        return api_key
    except FileNotFoundError:
        st.error("API í‚¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return ""
    except Exception as e:
        st.error(f"API í‚¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return ""


def get_selected_code(selected_nodes):
    selected_codes = []
    for node_label in selected_nodes:
        node = find_node(st.session_state.nodes, node_label)
        if node:
            if os.path.exists(node.code):  # íŒŒì¼ ê²½ë¡œê°€ ìœ íš¨í•œì§€ í™•ì¸
                file_content = read_file(node.code)
                if file_content:
                    selected_codes.append(
                        f"########################\n ìë£Œ ì´ë¦„ : {node.label} \n\n{file_content}")
            else:
                selected_codes.append(
                    f"########################\n ìë£Œ ì´ë¦„ : {node.label} \n\n{node.code}")
    return "\n\n".join(selected_codes)


def display_selected_codes(nodes):
    selected_codes = []
    for node_label in nodes:
        node = find_node(st.session_state.nodes, node_label)
        if node:
            if os.path.exists(node.code):  # íŒŒì¼ ê²½ë¡œê°€ ìœ íš¨í•œì§€ í™•ì¸
                file_content = read_file(node.code)
                if file_content:
                    selected_codes.append(
                        f"ìë£Œ ì´ë¦„ : {node.label} \n\n{file_content}")
            else:
                selected_codes.append(f"ìë£Œ ì´ë¦„ : {node.label} \n\n{node.code}")
    if selected_codes:
        code_text = "\n\n".join(selected_codes)
        st.text_area("ì„ íƒëœ ìë£Œì˜ ë‚´ìš©", code_text, height=500)
    else:
        st.write("ì„ íƒëœ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")


def download_json_file(nodes, file_name):
    try:
        nodes_data = [node.to_dict() for node in nodes]
        json_data = json.dumps(nodes_data, indent=2)
        b64 = base64.b64encode(json_data.encode("utf-8")).decode("utf-8")
        href = f'<a href="data:file/json;base64,{
            b64}" download="{file_name}">ë…¸ë“œ êµ¬ì¡° ë‹¤ìš´ë¡œë“œ</a>'
        return href
    except Exception as e:
        st.error(f"JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return ""


def load_nodes_from_json(json_data):
    try:
        nodes_data = json.loads(json_data)
        nodes = []
        for node_data in nodes_data:
            node = load_node_from_dict(node_data)
            nodes.append(node)
        return nodes
    except json.JSONDecodeError:
        st.error("ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ì…ë‹ˆë‹¤.")
        return []
    except Exception as e:
        st.error(f"JSON ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return []


def load_node_from_dict(node_data):
    node = Node(node_data['label'], node_data.get(
        'code', ''), id=node_data.get('value', node_data['label']))
    for child_data in node_data.get('children', []):
        child_node = load_node_from_dict(child_data)
        node.add_child(child_node)
    return node


def extract_node_labels_with_paths(nodes):
    labels = []
    for node in nodes:
        labels.append((os.path.basename(node.id), node.id))
        labels.extend(extract_node_labels_with_paths(node.children))
    return labels


def find_node(nodes, id):
    for node in nodes:
        if node.id == id:
            return node
        found_node = find_node(node.children, id)
        if found_node:
            return found_node
    return None


def find_node_by_path(nodes, path):
    for node in nodes:
        if node.id == path:
            return node
        found_node = find_node_by_path(node.children, path)
        if found_node:
            return found_node
    return None


def remove_node(nodes, id):
    for i, node in enumerate(nodes):
        if node.id == id:
            nodes.pop(i)
            remove_expanded_node(id)
            remove_expanded_children(node)
            return True
        if remove_node(node.children, id):
            return True
    return False


def remove_expanded_node(id):
    if id in st.session_state.expanded_nodes:
        st.session_state.expanded_nodes.remove(id)


def remove_expanded_children(node):
    for child in node.children:
        remove_expanded_node(child.id)
        remove_expanded_children(child)


def extract_all_node_labels(nodes):
    labels = []
    for node in nodes:
        labels.append(node.id)
        labels.extend(extract_all_node_labels(node.children))
    return labels


def is_label_exists(nodes, label):
    if label in extract_node_labels(nodes):
        return True
    return False


def chunk_text(text, chunk_size=500, overlap_size=100):
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap_size
    return chunks


# í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ì²­í¬ í¬ê¸°ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€
def calculate_chunk_size(text_length, desired_chunks=6, overlap_size=100):
    if text_length <= 0 or desired_chunks <= 0:
        return 500  # ê¸°ë³¸ ì²­í¬ í¬ê¸°
    chunk_size = (text_length + (desired_chunks - 1)
                  * overlap_size) // desired_chunks
    return chunk_size


def make_metaprompt(request):
    ANTHROPIC_API_KEY = load_api_key()
    MODEL_NAME = "claude-3-opus-20240229"
    CLIENT = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

    metaprompt = open("meta_prompt.txt", "r", encoding="utf-8").read()
    TASK = request
    VARIABLES = ["CODE", "REQUEST"]

    variable_string = ""
    for variable in VARIABLES:
        variable_string += "\n{$" + variable.upper() + "}"

    prompt = metaprompt.replace("{{TASK}}", TASK)
    assistant_partial = "<Inputs>"
    if variable_string:
        assistant_partial += variable_string + "\n</Inputs>\n<Instructions Structure>"

    st.subheader("ë©”íƒ€í”„ë¡¬í”„íŠ¸ ìƒì„±")
    st.write("ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ChatGPTë‚˜ Claudeì™€ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ë³µì‚¬í•˜ì—¬ ì•„ë˜ í…ìŠ¤íŠ¸ ì˜ì—­ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
    st.code(prompt + "\n" + assistant_partial, language="text")

    message = st.text_area("ChatGPT ë˜ëŠ” Claude ì¶œë ¥ ê²°ê³¼ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
    if st.button('ì½”ë“œë§Œ ë³µì‚¬'):
        global selected_code
        pyperclip.copy(selected_code)
    if message.strip() != "":
        extracted_prompt_template = extract_prompt(message)
        variables = extract_variables(message)

        remove_floating_variables_prompt = open(
            "remove_floating_variables_prompt.txt", "r", encoding="utf-8").read()

        floating_variables = find_free_floating_variables(
            extracted_prompt_template)

        st.write(floating_variables)
        if st.button('í”„ë¡¬í”„íŠ¸'):
            if len(floating_variables) > 0:
                extracted_prompt_template_old = extracted_prompt_template
                extracted_prompt_template_new = remove_inapt_floating_variables(
                    extracted_prompt_template, CLIENT, MODEL_NAME, remove_floating_variables_prompt)
                st.write("ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿:")
                st.code(extracted_prompt_template_new, language="text")

        variable_values = {}
        for variable in variables:
            variable_values[variable] = st.text_area(
                f"ë³€ìˆ˜ '{variable}'ì˜ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”.")

        prompt_with_variables = extracted_prompt_template
        for variable in variable_values:
            prompt_with_variables = prompt_with_variables.replace(
                "{" + variable + "}", variable_values[variable])

        st.subheader("ìµœì¢… í”„ë¡¬í”„íŠ¸")
        if st.button('ë³µì‚¬'):
            pyperclip.copy(prompt_with_variables + 'í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.')
        st.write("ìœ„ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ChatGPTë‚˜ Claudeì™€ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”.")


def process_column(client, model, messages):
    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model=model,
            messages=[{"role": m["role"], "content": m["content"]}
                      for m in messages],
            stream=True,
        )
        response = st.write_stream(stream)
        return response


def main():
    try:
        st.set_page_config(page_title="íŠ¸ë¦¬ ê¸°ë°˜ ìë£Œ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")
        st.title("íŠ¸ë¦¬ ê¸°ë°˜ ìë£Œ ê´€ë¦¬")

        if "nodes" not in st.session_state:
            st.session_state.nodes = [Node("START", "ì‹œì‘")]

        if "expanded_nodes" not in st.session_state:
            st.session_state.expanded_nodes = [
                node.id for node in st.session_state.nodes]

        favorite_directories = load_favorite_directories()

        with st.sidebar:
            st.subheader("ì¦ê²¨ì°¾ê¸° ê²½ë¡œ")
            selected_favorite_directory = st.selectbox(
                "ì¦ê²¨ì°¾ê¸° ê²½ë¡œ ì„ íƒ", favorite_directories)
            if selected_favorite_directory:
                st.write(f"ì„ íƒëœ ê²½ë¡œ: {selected_favorite_directory}")

            # st.subheader("ë…¸ë“œ ê´€ë¦¬")

            # st.subheader("ë…¸ë“œ ì¶”ê°€")
            node_labels_with_paths = extract_node_labels_with_paths(
                st.session_state.nodes)
            # parent_label = st.selectbox(
            #     "ë¶€ëª¨ ë…¸ë“œ ì„ íƒ", [label for label, _ in node_labels_with_paths])
            # label = st.text_input("ë…¸ë“œ ë ˆì´ë¸”")
            # code = st.text_area("ë‚´ìš© ë‚´ìš©")
            # if st.button("ë…¸ë“œ ì¶”ê°€"):
            #     if not is_label_exists(st.session_state.nodes, label):
            #         parent_path = next(
            #             path for label, path in node_labels_with_paths if label == parent_label)
            #         parent_node = find_node_by_path(
            #             st.session_state.nodes, parent_path)
            #         if parent_node:
            #             new_node = Node(label, code)
            #             parent_node.add_child(new_node)
            #             # .md íŒŒì¼ ìƒì„±
            #             file_path = os.path.join(parent_path, f"{label}.md")
            #             write_file(file_path, code)
            #             new_node.code = file_path
            #         else:
            #             new_node = Node(label, code)
            #             st.session_state.nodes.append(new_node)
            #             # .md íŒŒì¼ ìƒì„±
            #             file_path = f"{label}.md"
            #             write_file(file_path, code)
            #             new_node.code = file_path
            #         st.session_state.expanded_nodes.append(label)
            #     else:
            #         st.warning("ì¤‘ë³µëœ ë…¸ë“œ ë¼ë²¨ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë¼ë²¨ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")

            st.subheader("ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ ì¶”ê°€")
            directory_path = st.text_input(
                "ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥", value=selected_favorite_directory)
            st_allowed_extensions = st.multiselect(
                "í¬í•¨í•  íŒŒì¼ í™•ì¥ì ì„ íƒ", [".cs", ".py", ".txt", ".md"], default=[".cs", ".py", ".txt", ".md"])
            if st.button("ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ ì¶”ê°€"):
                if os.path.exists(directory_path):
                    # ë””ë ‰í† ë¦¬ ê²½ë¡œì™€ ì¼ì¹˜í•˜ëŠ” ë…¸ë“œë¥¼ ì°¾ì•„ì„œ ì‚­ì œ
                    nodes_to_remove = [
                        node for node in st.session_state.nodes if node.id.startswith(directory_path)]
                    for node in nodes_to_remove:
                        remove_node(st.session_state.nodes, node.id)

                    # ìƒˆë¡­ê²Œ ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ë¥¼ ì¶”ê°€
                    new_directory_node, _ = directory_to_tree(
                        directory_path, st_allowed_extensions)
                    st.session_state.nodes.append(new_directory_node)
                    st.session_state.expanded_nodes.append(
                        new_directory_node.id)
                else:
                    st.error("ë””ë ‰í† ë¦¬ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            st.subheader("ì¦ê²¨ì°¾ê¸° ê²½ë¡œë¥¼ ë…¸ë“œë¡œ ì¶”ê°€")
            if st.button("ì¦ê²¨ì°¾ê¸° ê²½ë¡œ ë…¸ë“œ ì¶”ê°€"):
                directory = selected_favorite_directory
                if os.path.exists(directory):
                    new_directory_node, _ = directory_to_tree(
                        directory, st_allowed_extensions)
                    st.session_state.nodes.append(new_directory_node)
                    st.session_state.expanded_nodes.append(
                        new_directory_node.id)
                else:
                    st.error(f"ë””ë ‰í† ë¦¬ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
                st.rerun()

            if st.button("ì¦ê²¨ì°¾ê¸° ëª¨ë“  ê²½ë¡œ ë…¸ë“œ ì¶”ê°€"):
                for directory in favorite_directories:
                    if os.path.exists(directory):
                        new_directory_node, _ = directory_to_tree(
                            directory, st_allowed_extensions)
                        st.session_state.nodes.append(new_directory_node)
                        st.session_state.expanded_nodes.append(
                            new_directory_node.id)
                    else:
                        st.error(f"ë””ë ‰í† ë¦¬ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
                st.rerun()

            # st.subheader("ë…¸ë“œ ìˆ˜ì •")
            # edit_label = st.selectbox(
            #     "ìˆ˜ì •í•  ë…¸ë“œ ì„ íƒ", [label for label, _ in node_labels_with_paths])
            # edit_path = next(
            #     path for label, path in node_labels_with_paths if label == edit_label)
            # edit_node = find_node_by_path(st.session_state.nodes, edit_path)
            # if edit_node:
            #     edit_code = st.text_area("ë‚´ìš© ë‚´ìš© ìˆ˜ì •", value=edit_node.code)
            #     if st.button("ë…¸ë“œ ìˆ˜ì •"):
            #         edit_node.code = edit_code
            #         # .md íŒŒì¼ ë‚´ìš© ìˆ˜ì •
            #         if os.path.exists(edit_node.code):
            #             write_file(edit_node.code, edit_code)
            # else:
            #     st.warning("ìˆ˜ì •í•  ë…¸ë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

            # st.subheader("ë…¸ë“œ ì‚­ì œ")
            # delete_label = st.selectbox(
            #     "ì‚­ì œí•  ë…¸ë“œ ì„ íƒ", [label for label, _ in node_labels_with_paths])
            # delete_path = next(
            #     path for label, path in node_labels_with_paths if label == delete_label)
            # if st.button("ë…¸ë“œ ì‚­ì œ"):
            #     if remove_node(st.session_state.nodes, delete_path):
            #         st.session_state.expanded_nodes.remove(delete_path)

            # st.subheader("ë‹¤ìš´ë¡œë“œ ë° ì—…ë¡œë“œ")
            # st.markdown(download_json_file(st.session_state.nodes,
            #             "nodes.json"), unsafe_allow_html=True)

            # uploaded_file = st.file_uploader("ë…¸ë“œ êµ¬ì¡° íŒŒì¼ ì—…ë¡œë“œ", type=["json"])
            # if uploaded_file is not None:
            #     json_data = uploaded_file.read().decode("utf-8")
            #     st.session_state.nodes = load_nodes_from_json(json_data)
            #     st.session_state.expanded_nodes = [
            #         node.id for node in st.session_state.nodes]

        if "checked_nodes" not in st.session_state:
            st.session_state.checked_nodes = []
        if "expanded_nodes" not in st.session_state:
            st.session_state.expanded_nodes = []

        tree_result = tree_select(
            [node.to_dict() for node in st.session_state.nodes],
            check_model='all',
            show_expand_all=False,
            expand_disabled=False,
            expanded=st.session_state.expanded_nodes,  # ì¶”ê°€ ë¶€ë¶„
            checked=st.session_state.checked_nodes  # ì¶”ê°€ ë¶€ë¶„
        )

        st.session_state.checked_nodes = tree_result.get('checked', [])
        st.session_state.expanded_nodes = tree_result.get('expanded', [])

        # st.code([node.to_dict() for node in st.session_state.nodes])
        prompts = load_prompts()

        selected_nodes = tree_result.get('checked', [])
        st.subheader("ì„ íƒëœ ìë£Œì˜ ë‚´ìš©")

        # selected_nodesì¤‘ í´ë”ê°€ ì•„ë‹Œ íŒŒì¼ë§Œ ì„ íƒí•˜ë„ë¡ í•¨
        # \ ë¡œ êµ¬ë¶„í•˜ê³  ë§ˆì§€ë§‰ ì¡°ê°ì— .ì´ ìˆìœ¼ë©´ íŒŒì¼ë¡œ ê²°ì •
        # íŒŒì¼ë§Œ ì„ íƒí•˜ëŠ” í•¨ìˆ˜
        def select_files(nodes):
            files = []
            for node in nodes:
                # \ë¡œ ê²½ë¡œ êµ¬ë¶„
                parts = node.split("\\")
                # ë§ˆì§€ë§‰ ì¡°ê°ì— .ì´ ìˆìœ¼ë©´ íŒŒì¼ë¡œ ê°„ì£¼
                if "." in parts[-1]:
                    files.append(parts[-1])
            return files

        st.write(select_files(selected_nodes))

        request = st.text_area("ìš”ì²­ ì…ë ¥", height=100)

        global selected_code
        selected_code = get_selected_code(selected_nodes)
        prompt = f"{selected_code}\n\n"

        # ìš”ì²­ í”„ë¡¬í”„íŠ¸ ì•ì— ì„ íƒí•˜ê²Œ í•˜ëŠ” ë¶€ë¶„ ì¶”ê°€
        st.subheader("ìš”ì²­ í”„ë¡¬í”„íŠ¸ ì•ì— ìœ„ì¹˜ì‹œí‚¬ ë…¸ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”")
        selected_specific_node_label = st.selectbox(
            "íŠ¹ì • ë…¸ë“œ ì„ íƒ", [label for label, _ in node_labels_with_paths])
        specific_node_path = next(
            path for label, path in node_labels_with_paths if label == selected_specific_node_label)
        specific_node = find_node_by_path(
            st.session_state.nodes, specific_node_path)

        specific_node_content = ""
        if specific_node:
            if os.path.exists(specific_node.code):
                specific_node_content = read_file(specific_node.code)
            else:
                specific_node_content = specific_node.code

        for prompt_name, prompt_content in prompts.items():
            use_prompt = st.checkbox(f"{prompt_name} ì‚¬ìš©")
            if use_prompt:
                prompt += f"{prompt_content}\n\n"

        prompt += f"[ìš”ì²­: {request}]\n\n"

        # íŠ¹ì • ë…¸ë“œ ë‚´ìš©ì„ ë§ˆì§€ë§‰ì— ì¶”ê°€
        prompt += f"########################\n ìë£Œ ì´ë¦„ : {
            specific_node.label} \n\n{specific_node_content}"

        st.session_state['prompt'] = prompt
        if st.button('í”„ë¡¬í”„íŠ¸ ë³µì‚¬'):
            pyperclip.copy(prompt)
        if st.button('í”„ë¡¬í”„íŠ¸ í™•ì¸'):
            st.code(prompt, language="python")

        tab1, tab2, tab3, tab4, tab5 = st.tabs(
            ["ì„ íƒëœ ìë£Œ", "ë©”íƒ€í”„ë¡¬í”„íŠ¸ ìƒì„±", "í”„ë¡¬í”„íŠ¸ í–¥ìƒ", "í…ìŠ¤íŠ¸ ë³€í™˜", "ë‹¤ì¤‘ ì±„íŒ…"])
        with tab1:
            display_selected_codes(selected_nodes)
        with tab2:
            make_metaprompt(request)

        with tab3:
            st.write("í”„ë¡¬í”„íŠ¸ í–¥ìƒ")
            user_prompt = st.text_area("í”„ë¡¬í”„íŠ¸ ì…ë ¥", height=100)

            ANTHROPIC_API_KEY = load_api_key()
            MODEL_NAME = "claude-3-sonnet-20240229"
            CLIENT = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

            if st.button("í”„ë¡¬í”„íŠ¸ í–¥ìƒ"):
                improve_prompt = open(
                    "prompt_improvement.txt", "r", encoding="utf-8").read()
                message = CLIENT.messages.create(
                    model=MODEL_NAME,
                    messages=[{'role': "user", "content": improve_prompt.replace(
                        "{$REQUEST}", user_prompt)}],
                    max_tokens=4096,
                    temperature=0
                ).content[0].text
                st.write(message)
                pyperclip.copy(message)

        with tab4:
            st.write("í…ìŠ¤íŠ¸ ì •ë¦¬")
            text_to_convert = st.text_area("ë³€í™˜í•  í…ìŠ¤íŠ¸ ì…ë ¥", height=200)

            # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ì²­í¬ í¬ê¸° ìë™ ê³„ì‚°
            if text_to_convert:
                default_chunk_size = calculate_chunk_size(len(text_to_convert))
            else:
                default_chunk_size = 1000

            # ìŠ¬ë¼ì´ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í¬ í¬ê¸°ì™€ ì˜¤ë²„ë© í¬ê¸°ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë„ë¡ í•¨
            max_chunk_size = 8000
            if default_chunk_size > max_chunk_size:
                default_chunk_size = max_chunk_size
            chunk_size = st.slider(
                "ì²­í¬ í¬ê¸°", min_value=100, max_value=max_chunk_size, value=default_chunk_size, step=1000)
            over_lap_size = st.slider(
                "ì˜¤ë²„ë© í¬ê¸°", min_value=0, max_value=500, value=100, step=10)

            # í…ìŠ¤íŠ¸ ê¸¸ì´ í‘œì‹œ
            if text_to_convert:
                st.write(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_to_convert)}")
                # ì²­í¬ ê°œìˆ˜
                chunks = chunk_text(
                    text_to_convert, chunk_size=chunk_size, overlap_size=over_lap_size)
                st.write(f"ì²­í¬ ê°œìˆ˜: {len(chunks)}")

            if st.button("í…ìŠ¤íŠ¸ ì •ë¦¬"):
                api_key_filepath = 'gemini_api_key.txt'
                model_name = 'models/gemini-1.5-flash-latest'
                api_key = load_gemini_api_key(api_key_filepath)
                configure_genai(api_key)
                model = get_model(model_name)

                chunks = chunk_text(
                    text_to_convert, chunk_size=chunk_size, overlap_size=over_lap_size)
                max_concurrent_requests = 15

                progress_bar = st.progress(0)
                total_chunks = len(chunks)
                processed_chunks = 0

                with st.spinner(f"í…ìŠ¤íŠ¸ ì •ë¦¬ ì¤‘..."):
                    with concurrent.futures.ThreadPoolExecutor(max_workers=max_concurrent_requests) as executor:
                        futures = []
                        for i, chunk in enumerate(chunks):
                            futures.append(
                                (i, executor.submit(generate_markdown, model, chunk)))
                            if (i + 1) % max_concurrent_requests == 0:
                                for index, future in futures:
                                    response = future.result()
                                    markdown_text = process_response(response)
                                    chunks[index] = markdown_text
                                    processed_chunks += 1
                                    progress_bar.progress(
                                        processed_chunks / total_chunks)
                                futures = []

                        # ë‚¨ì€ ì²­í¬ ì²˜ë¦¬
                        for index, future in futures:
                            response = future.result()
                            markdown_text = process_response(response)
                            chunks[index] = markdown_text
                            processed_chunks += 1
                            progress_bar.progress(
                                processed_chunks / total_chunks)

                    markdown_result = "\n\n".join(chunks)
                    inner_tab1, inner_tab2 = st.tabs(["ì½”ë“œ", "ë§ˆí¬ë‹¤ìš´"])
                    with inner_tab1:
                        st.code(markdown_result)
                    with inner_tab2:
                        st.markdown(markdown_result)

                    b64 = base64.b64encode(markdown_result.encode()).decode()
                    href = f'<a href="data:file/markdown;base64,{
                        b64}" download="markdown_result.md">ë§ˆí¬ë‹¤ìš´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ</a>'
                    st.markdown(href, unsafe_allow_html=True)

        with tab5:
            # í”„ë¡¬í”„íŠ¸ë¥¼ ë³µìˆ˜ ê°œì˜ APIì— ì „ë‹¬í•˜ì—¬ ê²°ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€
            # text ë¡œë“œ
            openapi_key = load_openai_api_key()
            client = openai.Client(api_key=openapi_key)
            st.session_state['openai_model'] = "gpt-4o"

            st.session_state.messages = []

            st.session_state.messages.append(
                {"role": "user", "content": prompt})

            def process_column():
                with st.chat_message("assistant"):
                    stream = client.chat.completions.create(
                        model=st.session_state["openai_model"],
                        messages=[
                            {"role": m["role"], "content": m["content"]}
                            for m in st.session_state.messages
                        ],
                        stream=True,
                    )
                    response = st.write_stream(stream)
            number_of_tabs = st.slider("íƒ­ ìˆ˜", 1, 4, 2)

            chat_tabs = st.tabs([f"íƒ­ {i+1}" for i in range(number_of_tabs)])
            if st.button("ì „ì†¡"):
                for i in range(number_of_tabs):
                    with chat_tabs[i]:
                        process_column()

    except Exception as e:
        st.error(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


if __name__ == "__main__":
    main()
